{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/quctngngvng/autoconfig?scriptVersionId=145923819\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-10T04:18:49.227142Z","iopub.execute_input":"2023-10-10T04:18:49.227552Z","iopub.status.idle":"2023-10-10T04:18:49.694409Z","shell.execute_reply.started":"2023-10-10T04:18:49.227521Z","shell.execute_reply":"2023-10-10T04:18:49.69343Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Config, GPT2Model\nfrom transformers import AutoConfig, AutoModelForMultipleChoice\nfrom transformers import AutoTokenizer,AutoConfig,AutoModel","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:18:51.989474Z","iopub.execute_input":"2023-10-10T04:18:51.990799Z","iopub.status.idle":"2023-10-10T04:18:58.788733Z","shell.execute_reply.started":"2023-10-10T04:18:51.990758Z","shell.execute_reply":"2023-10-10T04:18:58.787778Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig, TFAutoModel,AutoModel\n\nconfig = AutoConfig.from_pretrained('bert-base-uncased')\n\nmodel = TFAutoModel.from_config(config)\n\nmodel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    optimizer=tf.keras.optimizers.RMSprop(),\n    metrics=[\"accuracy\"],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/gpt-neo-1.3B-vietnamese-news\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confix_Viet = AutoConfig.from_pretrained(\"VietAI/gpt-neo-1.3B-vietnamese-news\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confix_Viet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = AutoModel.from_config(confix_Viet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"confix_Viet.architectures[0] = 'gpt2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModel.from_config(confix_Viet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Initializing a GPT2 configuration\nconfiguration = GPT2Config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configuration","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.build()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Download configuration from huggingface.co and cache.\nconfig = AutoConfig.from_pretrained(\"bert-base-cased\")\nmodel = AutoModelForMultipleChoice.from_config(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\"mr4/phobert-base-vi-sentiment-analysis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenni = AutoTokenizer.from_pretrained(\"mr4/phobert-base-vi-sentiment-analysis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenni","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multipleChoiceModel = AutoModelForMultipleChoice.from_config(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST PRETRAIN MODEL VIET","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet = AutoTokenizer.from_pretrained('mr4/phobert-base-vi-sentiment-analysis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configBase = AutoConfig.from_pretrained('bert-base-cased')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configBase","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet.model_max_length = 768","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet_config = {\n    \"vocab_file\": tokenizerViet.vocab_files_names[\"vocab_file\"],\n    \"merges_file\": tokenizerViet.vocab_files_names[\"merges_file\"],\n    \"tokenizer_class\": type(tokenizerViet).__name__,\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configBase.tokenizer_class = tokenizerViet_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configBase.model_type","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configBase","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModel.from_config(configBase)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizerViet.push_to_hub(repo_id = 'VuongQuoc/bert-base-VN',token = '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')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(repo_id = 'VuongQuoc/bert-base-VN',token = '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')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test push mode and token VI**","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained('VuongQuoc/bert-base-VN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(config.finetuning_task)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.num_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('VuongQuoc/bert-base-VN')","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:19:12.857257Z","iopub.execute_input":"2023-10-10T04:19:12.85857Z","iopub.status.idle":"2023-10-10T04:19:13.841425Z","shell.execute_reply.started":"2023-10-10T04:19:12.858517Z","shell.execute_reply":"2023-10-10T04:19:13.840479Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# model = AutoModel.from_pretrained('VuongQuoc/bert-base-VN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val = \"Ngày hôm này thế nào\"\nraw_inputs = [val]\ninputs = tokenizer(raw_inputs, padding=True,\n                   truncation=False, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:19:17.065044Z","iopub.execute_input":"2023-10-10T04:19:17.065647Z","iopub.status.idle":"2023-10-10T04:19:17.076853Z","shell.execute_reply.started":"2023-10-10T04:19:17.065609Z","shell.execute_reply":"2023-10-10T04:19:17.075414Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"out = model(**inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out['last_hidden_state'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config_multicchoice = AutoConfig.from_pretrained('VuongQuoc/bert-base-VN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config_multicchoice.vocab_size = tokenizer.vocab_size +1\n# config_multicchoice.push_to_hub('VuongQuoc/bert-base-VN',token = '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')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelChoice = AutoModelForMultipleChoice.from_pretrained('VuongQuoc/bert-base-VN',ignore_mismatched_sizes=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:20:45.10471Z","iopub.execute_input":"2023-10-10T04:20:45.105108Z","iopub.status.idle":"2023-10-10T04:20:47.705649Z","shell.execute_reply.started":"2023-10-10T04:20:45.105062Z","shell.execute_reply":"2023-10-10T04:20:47.704631Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of BertForMultipleChoice were not initialized from the model checkpoint at VuongQuoc/bert-base-VN and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForMultipleChoice were not initialized from the model checkpoint at VuongQuoc/bert-base-VN and are newly initialized because the shapes did not match:\n- embeddings.word_embeddings.weight: found shape torch.Size([28996, 768]) in the checkpoint and torch.Size([64001, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"modelChoice","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:21:52.497856Z","iopub.execute_input":"2023-10-10T04:21:52.498565Z","iopub.status.idle":"2023-10-10T04:21:52.509335Z","shell.execute_reply.started":"2023-10-10T04:21:52.498525Z","shell.execute_reply":"2023-10-10T04:21:52.507833Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"BertForMultipleChoice(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"prompt = \"Bác Hồ là người nước nào ?.\"\ncandidate1 = \"Việt Nam\"\ncandidate2 = \"Mỹ\"\ncandidate3 = 'Việt Nam'","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:25.070107Z","iopub.execute_input":"2023-10-10T04:39:25.070611Z","iopub.status.idle":"2023-10-10T04:39:25.076332Z","shell.execute_reply.started":"2023-10-10T04:39:25.070575Z","shell.execute_reply":"2023-10-10T04:39:25.074919Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"VuongQuoc/bert-base-VN\")\ninputs = tokenizer([[prompt, candidate1], [prompt, candidate2],[prompt, candidate3]], return_tensors=\"pt\", padding=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:28.049858Z","iopub.execute_input":"2023-10-10T04:39:28.050295Z","iopub.status.idle":"2023-10-10T04:39:28.390453Z","shell.execute_reply.started":"2023-10-10T04:39:28.050264Z","shell.execute_reply":"2023-10-10T04:39:28.388918Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"inputs['input_ids'] = inputs['input_ids'].unsqueeze(0)\ninputs['token_type_ids'] = inputs['token_type_ids'].unsqueeze(0)\ninputs['attention_mask'] = inputs['attention_mask'].unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:34.662615Z","iopub.execute_input":"2023-10-10T04:39:34.663034Z","iopub.status.idle":"2023-10-10T04:39:34.670751Z","shell.execute_reply.started":"2023-10-10T04:39:34.663003Z","shell.execute_reply":"2023-10-10T04:39:34.668999Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"inputs['input_ids'].shape","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:37.099695Z","iopub.execute_input":"2023-10-10T04:39:37.100269Z","iopub.status.idle":"2023-10-10T04:39:37.109824Z","shell.execute_reply.started":"2023-10-10T04:39:37.100223Z","shell.execute_reply":"2023-10-10T04:39:37.108417Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 3, 14])"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nlabels = torch.tensor(0).unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:40.015286Z","iopub.execute_input":"2023-10-10T04:39:40.015735Z","iopub.status.idle":"2023-10-10T04:39:40.021837Z","shell.execute_reply.started":"2023-10-10T04:39:40.01569Z","shell.execute_reply":"2023-10-10T04:39:40.020578Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:47.660957Z","iopub.execute_input":"2023-10-10T04:39:47.661384Z","iopub.status.idle":"2023-10-10T04:39:47.671391Z","shell.execute_reply.started":"2023-10-10T04:39:47.661352Z","shell.execute_reply":"2023-10-10T04:39:47.669942Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"tensor([0])"},"metadata":{}}]},{"cell_type":"code","source":"out = modelChoice(**inputs)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:50.343195Z","iopub.execute_input":"2023-10-10T04:39:50.344007Z","iopub.status.idle":"2023-10-10T04:39:50.540136Z","shell.execute_reply.started":"2023-10-10T04:39:50.343959Z","shell.execute_reply":"2023-10-10T04:39:50.539236Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"out","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:39:53.252147Z","iopub.execute_input":"2023-10-10T04:39:53.25255Z","iopub.status.idle":"2023-10-10T04:39:53.26113Z","shell.execute_reply.started":"2023-10-10T04:39:53.252519Z","shell.execute_reply":"2023-10-10T04:39:53.260061Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"MultipleChoiceModelOutput(loss=None, logits=tensor([[ 0.0421, -0.0345,  0.0421]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"out = modelChoice(**inputs,labels = labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:40:08.727382Z","iopub.execute_input":"2023-10-10T04:40:08.727882Z","iopub.status.idle":"2023-10-10T04:40:08.87493Z","shell.execute_reply.started":"2023-10-10T04:40:08.72784Z","shell.execute_reply":"2023-10-10T04:40:08.873692Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"out.logits","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:40:12.013713Z","iopub.execute_input":"2023-10-10T04:40:12.014167Z","iopub.status.idle":"2023-10-10T04:40:12.025314Z","shell.execute_reply.started":"2023-10-10T04:40:12.014132Z","shell.execute_reply":"2023-10-10T04:40:12.02292Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0421, -0.0345,  0.0421]], grad_fn=<ViewBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"out.logits","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:40:18.800455Z","iopub.execute_input":"2023-10-10T04:40:18.800852Z","iopub.status.idle":"2023-10-10T04:40:18.811899Z","shell.execute_reply.started":"2023-10-10T04:40:18.800824Z","shell.execute_reply":"2023-10-10T04:40:18.809813Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0421, -0.0345,  0.0421]], grad_fn=<ViewBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:41:44.77823Z","iopub.execute_input":"2023-10-10T04:41:44.778689Z","iopub.status.idle":"2023-10-10T04:41:44.784014Z","shell.execute_reply.started":"2023-10-10T04:41:44.77866Z","shell.execute_reply":"2023-10-10T04:41:44.782437Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html","metadata":{}},{"cell_type":"code","source":"m = nn.LogSoftmax(dim=1)\nloss = nn.NLLLoss()","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:40:26.818602Z","iopub.execute_input":"2023-10-10T04:40:26.819024Z","iopub.status.idle":"2023-10-10T04:40:26.824728Z","shell.execute_reply.started":"2023-10-10T04:40:26.818991Z","shell.execute_reply":"2023-10-10T04:40:26.823788Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"softmax = F.softmax(out.logits)\ntorch.log(softmax)\nprint(out.logits,m(out.logits))","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:43:26.965963Z","iopub.execute_input":"2023-10-10T04:43:26.966377Z","iopub.status.idle":"2023-10-10T04:43:26.974972Z","shell.execute_reply.started":"2023-10-10T04:43:26.966348Z","shell.execute_reply":"2023-10-10T04:43:26.973881Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"tensor([[ 0.0421, -0.0345,  0.0421]], grad_fn=<ViewBackward0>) tensor([[-1.0737, -1.1503, -1.0737]], grad_fn=<LogSoftmaxBackward0>)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_2290/700195406.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  softmax = F.softmax(out.logits)\n","output_type":"stream"}]},{"cell_type":"code","source":"output_loss = loss(m(out.logits), labels)","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:35:20.212741Z","iopub.execute_input":"2023-10-10T04:35:20.213181Z","iopub.status.idle":"2023-10-10T04:35:20.219149Z","shell.execute_reply.started":"2023-10-10T04:35:20.213152Z","shell.execute_reply":"2023-10-10T04:35:20.217967Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"output_loss","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:35:22.501374Z","iopub.execute_input":"2023-10-10T04:35:22.501791Z","iopub.status.idle":"2023-10-10T04:35:22.511118Z","shell.execute_reply.started":"2023-10-10T04:35:22.501729Z","shell.execute_reply":"2023-10-10T04:35:22.510198Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor(0.7210, grad_fn=<NllLossBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"target = torch.empty(5, 8, 8, dtype=torch.long).random_(0, 3)","metadata":{"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"tensor([[[1, 1, 0, 1, 0, 0, 0, 0],\n         [0, 2, 2, 1, 0, 1, 1, 2],\n         [1, 0, 1, 1, 0, 0, 2, 1],\n         [2, 0, 2, 0, 1, 0, 0, 0],\n         [1, 1, 2, 1, 2, 2, 2, 1],\n         [0, 1, 0, 1, 2, 1, 2, 2],\n         [0, 2, 1, 0, 0, 0, 0, 0],\n         [1, 1, 0, 2, 2, 2, 2, 2]],\n\n        [[1, 1, 0, 2, 0, 0, 1, 2],\n         [0, 1, 0, 0, 1, 0, 1, 2],\n         [0, 1, 1, 0, 0, 0, 0, 2],\n         [0, 1, 2, 1, 1, 2, 2, 2],\n         [2, 1, 2, 0, 2, 2, 2, 0],\n         [0, 2, 1, 2, 2, 2, 1, 1],\n         [0, 0, 2, 1, 2, 2, 1, 1],\n         [2, 2, 0, 1, 2, 2, 1, 0]],\n\n        [[2, 2, 2, 2, 1, 0, 2, 2],\n         [1, 2, 1, 2, 2, 0, 0, 0],\n         [0, 1, 2, 0, 0, 1, 2, 2],\n         [0, 1, 1, 2, 0, 1, 1, 0],\n         [2, 2, 0, 2, 1, 0, 2, 1],\n         [2, 2, 2, 1, 1, 1, 1, 0],\n         [1, 2, 0, 1, 0, 1, 1, 0],\n         [2, 0, 0, 0, 2, 0, 2, 0]],\n\n        [[2, 0, 0, 1, 0, 0, 0, 0],\n         [0, 1, 2, 2, 0, 0, 0, 1],\n         [2, 1, 0, 0, 0, 2, 0, 0],\n         [0, 1, 2, 1, 2, 1, 2, 2],\n         [2, 1, 0, 1, 0, 2, 1, 1],\n         [0, 1, 1, 1, 1, 2, 2, 2],\n         [1, 2, 1, 0, 0, 0, 2, 2],\n         [1, 1, 0, 1, 1, 2, 0, 2]],\n\n        [[2, 1, 0, 1, 2, 2, 1, 1],\n         [1, 2, 0, 1, 0, 0, 1, 2],\n         [0, 2, 1, 1, 1, 2, 0, 0],\n         [1, 2, 0, 1, 1, 2, 1, 2],\n         [1, 2, 0, 1, 1, 0, 0, 1],\n         [1, 0, 1, 2, 2, 2, 1, 1],\n         [2, 0, 2, 2, 0, 1, 2, 2],\n         [1, 0, 0, 0, 1, 2, 1, 1]]])"},"metadata":{}}]},{"cell_type":"code","source":"target.shape  ","metadata":{"execution":{"iopub.status.busy":"2023-10-10T04:48:42.810026Z","iopub.execute_input":"2023-10-10T04:48:42.810455Z","iopub.status.idle":"2023-10-10T04:48:42.817254Z","shell.execute_reply.started":"2023-10-10T04:48:42.810425Z","shell.execute_reply":"2023-10-10T04:48:42.816135Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"torch.Size([5, 8, 8])"},"metadata":{}}]}]}